{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e51af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "\n",
    "import pickle\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, LassoCV, RidgeCV, ElasticNetCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from xgboost import XGBRegressor, XGBRFRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.base import clone\n",
    "import time\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9a1ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./combine_2010_2025\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646d612e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Excludes positions with heavier players\n",
    "# df = df[df[\"Pos\"].isin([\"WR\", \"CB\", \"RB\", \"FS\", \"OLB\", \"ILB\", \"SS\", \"TE\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb01429",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data\n",
    "data = df[[\"Vertical\", \"Ht\", \"Wt\"]].copy()\n",
    "data[\"Relative-mass\"] = df[\"Wt\"] / df[\"Ht\"] ** 3\n",
    "data[\"Relative-vertical\"] = df[\"Vertical\"] / df[\"Ht\"]\n",
    "data[\"40yd\"] = df[\"40yd\"]\n",
    "data = data.dropna()\n",
    "\n",
    "X_original, y = data.drop([\"40yd\"], axis=\"columns\"), data[\"40yd\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96fe45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine potential feature combinations\n",
    "feature_names = X_original.columns\n",
    "feature_combinations = []\n",
    "for i in range(1, len(feature_names)):\n",
    "    i_length_combinations =itertools.combinations(feature_names, i)\n",
    "    for combination in i_length_combinations:\n",
    "        feature_combinations.append(combination)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515efc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02ffe38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model definition\n",
    "linear_regression = GridSearchCV(LinearRegression(), param_grid={})\n",
    "lasso = GridSearchCV(LassoCV(), param_grid={})\n",
    "ridge = GridSearchCV(RidgeCV(), param_grid={})\n",
    "elastic_net = GridSearchCV(ElasticNetCV(), param_grid={})\n",
    "polynomial_regression = GridSearchCV(make_pipeline(PolynomialFeatures(), LinearRegression()),\n",
    "                                     param_grid={\"polynomialfeatures__degree\": [2, 3, 4, 5, 6]})\n",
    "polynomial_lasso = GridSearchCV(make_pipeline(PolynomialFeatures(), LassoCV(max_iter=100000)),\n",
    "                                     param_grid={\"polynomialfeatures__degree\": [2, 3, 4, 5, 6]})\n",
    "polynomial_ridge = GridSearchCV(make_pipeline(PolynomialFeatures(), RidgeCV()),\n",
    "                                     param_grid={\"polynomialfeatures__degree\": [2, 3, 4, 5, 6]})\n",
    "polynomial_elastic_net = GridSearchCV(make_pipeline(PolynomialFeatures(), ElasticNetCV(max_iter=100000)),\n",
    "                                     param_grid={\"polynomialfeatures__degree\": [2, 3, 4, 5, 6]})\n",
    "\n",
    "random_forest = GridSearchCV(RandomForestRegressor(), {\n",
    "    \"n_estimators\": [1, 10, 50, 100, 200],\n",
    "    \"max_depth\": [5, 7, 10, 15, None],\n",
    "    \"max_features\": [\"sqrt\", None],\n",
    "    \"bootstrap\": [False, True]\n",
    "})\n",
    "\n",
    "extra_trees = GridSearchCV(ExtraTreesRegressor(), {\n",
    "    \"n_estimators\": [10, 50, 100, 200],    \n",
    "    \"max_depth\": [5, 7, 10, 15, None],\n",
    "    \"max_features\": [\"sqrt\", None],\n",
    "    \"bootstrap\": [False, True]\n",
    "})\n",
    "\n",
    "xgb = GridSearchCV(XGBRegressor(), {\n",
    "    \"n_estimators\": [10, 50, 100, 200],\n",
    "    \"max_depth\": [5, 7, 10, None],\n",
    "    \"learning_rate\": [0.1, 0.05, 0.02, 0.01],\n",
    "    \"tree_method\": [\"auto\", \"approx\"]\n",
    "})\n",
    "\n",
    "xgbrf = GridSearchCV(XGBRFRegressor(), {\n",
    "    \"n_estimators\": [10, 50, 100, 200],\n",
    "    \"max_depth\": [5, 7, 10, 15, None],\n",
    "    \"tree_method\": [\"auto\", \"approx\"]\n",
    "})\n",
    "\n",
    "mlp = GridSearchCV(MLPRegressor(), {\n",
    "    \"\"\n",
    "    \"max_iter\": [20000],\n",
    "    \"solver\": [\"lbfgs\", \"adam\"],\n",
    "    \"hidden_layer_sizes\": [(100, 50, 20), (200, 100, 50), (200, 100, 50, 25), (120, 90, 68, 51), (120, 90, 68, 51, 39, 25)]\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7646eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns represent GridSearches for different models\n",
    "# Rows represent feature combinations used\n",
    "models_df = pd.DataFrame({\n",
    "    \"LinearRegression\": [clone(linear_regression) for _ in range(len(feature_combinations))],\n",
    "    \"LassoCV\": [clone(lasso) for _ in range(len(feature_combinations))],\n",
    "    \"RidgeCV\": [clone(ridge) for _ in range(len(feature_combinations))],\n",
    "    \"ElasticNetCV\": [clone(elastic_net) for _ in range(len(feature_combinations))],\n",
    "    \"PolynomialRegression\": [clone(polynomial_regression) for _ in range(len(feature_combinations))],\n",
    "    \"PolynomialLasso\": [clone(polynomial_lasso) for _ in range(len(feature_combinations))],\n",
    "    \"PolynomialRidge\": [clone(polynomial_ridge) for _ in range(len(feature_combinations))],\n",
    "    \"PolynomialElasticNet\": [clone(polynomial_elastic_net) for _ in range(len(feature_combinations))],\n",
    "    \"RandomForestRegressor\": [clone(random_forest) for _ in range(len(feature_combinations))],\n",
    "    \"ExtraTreesRegressor\": [clone(extra_trees) for _ in range(len(feature_combinations))],\n",
    "    \"XGBRegressor\": [clone(xgb) for _ in range(len(feature_combinations))],\n",
    "    \"XGBRFRegressor\": [clone(xgbrf) for _ in range(len(feature_combinations))],\n",
    "    \"MLPRegressor\": [clone(mlp) for _ in range(len(feature_combinations))]\n",
    "})\n",
    "\n",
    "features_df = pd.DataFrame({\n",
    "    \"Features\": feature_combinations\n",
    "})\n",
    "features_df[\"Scaler\"] = features_df[\"Features\"].apply(lambda _: StandardScaler()) # type: ignore\n",
    "for i in features_df.index:\n",
    "    features = features_df.loc[i, \"Features\"]\n",
    "    scaler = features_df.loc[i, \"Scaler\"]\n",
    "    X = X_original[list(features)].copy() # type: ignore\n",
    "    scaler.fit(X) # type: ignore\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1644f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def search_models(models_df: pd.DataFrame) -> None:\n",
    "    for i in models_df.index:\n",
    "        print(f\"{i}/{models_df.shape[0]}\")\n",
    "        features = features_df.loc[i, \"Features\"]\n",
    "        scaler = features_df.loc[i, \"Scaler\"]\n",
    "        X = X_original[list(features)].copy() # type: ignore\n",
    "        X = scaler.transform(X) # type: ignore\n",
    "        for col in models_df.columns:\n",
    "            start_time = time.time()\n",
    "            model = models_df.loc[i, col]\n",
    "            model.fit(X, y) # type: ignore\n",
    "            print(f\"Training {col} complete in {round(time.time() - start_time, 2)} seconds\")\n",
    "            score = model.cv_results_[\"mean_test_score\"].max() # type: ignore\n",
    "            print(f\"Score: {score}\")\n",
    "            print()\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033e809c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take some fast models first, to see which feature combinations yield good results\n",
    "fast_models_slice = models_df.loc[:, [\n",
    "    \"LinearRegression\", \n",
    "    \"RidgeCV\", \n",
    "    \"ElasticNetCV\", \n",
    "    \"PolynomialRegression\", \n",
    "    \"PolynomialRidge\", \n",
    "    \"PolynomialElasticNet\", \n",
    "    \"XGBRegressor\"\n",
    "]]\n",
    "\n",
    "# Remaining, slower models will only be trained on the best feature combinations\n",
    "remaining_models_slice = models_df.drop(fast_models_slice.columns, axis=\"columns\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca68b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_models(fast_models_slice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79312763",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only feature combinations that yield scores above a threshold\n",
    "chosen_combination_indices = []\n",
    "scores = []\n",
    "for i in fast_models_slice.index:\n",
    "    scores.append(fast_models_slice.loc[i, :].apply(lambda s: s.cv_results_[\"mean_test_score\"].max()).max())\n",
    "\n",
    "percentile_90 = np.percentile(scores, 90)\n",
    "\n",
    "for i in fast_models_slice.index:\n",
    "    if fast_models_slice.loc[i, :].apply(lambda s: s.cv_results_[\"mean_test_score\"].max()).max() > percentile_90: # type: ignore\n",
    "        chosen_combination_indices.append(i)\n",
    "\n",
    "features_df.loc[chosen_combination_indices]\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f45eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_indices_remaining_models_slice = remaining_models_slice.loc[chosen_combination_indices]\n",
    "search_models(chosen_indices_remaining_models_slice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc20f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_features_df = models_df.loc[chosen_combination_indices].reset_index()\n",
    "final_models_df = models_df.loc[chosen_combination_indices].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247b21d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "with open(\"pickled_models/model_selection.pickle\", \"wb\") as file:\n",
    "    pickle.dump((final_features_df, final_models_df), file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
